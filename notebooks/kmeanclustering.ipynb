{
 "metadata": {
  "name": "",
  "signature": "sha256:a14f12a2429a93008b20119dcfba02b0c56029b6140c2a21434994bc1795745c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "from sklearn.utils import check_random_state\n",
      "from sklearn.utils.fixes import bincount\n",
      "from sklearn.metrics.pairwise import euclidean_distances"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "cannot import name bincount",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-ea3d86a79329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbincount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meuclidean_distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mImportError\u001b[0m: cannot import name bincount"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def distance_function(v1, v2):\n",
      "  #TODO: IMPLEMENT\n",
      "  # Write a function to compute the euclidean distance between two vectors, v1 and v2\n",
      "    return np.linalg.norm(v1-v2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _compute_labels_and_score(X, centers):\n",
      "    \"\"\"\n",
      "\n",
      "    Compute the labels and the current score of the given samples and centers\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    X: float64 array-like or CSR sparse matrix, shape (n_samples, n_features)\n",
      "        The input samples to assign to the labels.\n",
      "\n",
      "    centers: float64 array, shape (k, n_features)\n",
      "        The cluster centers.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    labels: int array of shape(n)\n",
      "        The resulting assignment\n",
      "\n",
      "    score: float\n",
      "        The value of the score criterion with the assignment\n",
      "        The score (sum of squared distances to the centers).\n",
      "    \"\"\"\n",
      "    n_clusters = centers.shape[0]\n",
      "    n_samples = X.shape[0]\n",
      "    score = 0.0\n",
      "\n",
      "    # set the default value of centers to -1 to be able to detect errors\n",
      "    labels = -np.ones(n_samples, np.int32)\n",
      "    #TODO: IMPLEMENT\n",
      "    for sample_idx in xrange(n_samples):\n",
      "        min_dist = -1\n",
      "        for center_idx in xrange(n_clusters):\n",
      "            dist = distance_function(X[sample_idx], centers[center_idx])\n",
      "            if min_dist == -1 or dist < min_dist:\n",
      "                min_dist = dist\n",
      "                labels[sample_idx] = center_idx\n",
      "        score += min_dist\n",
      "\n",
      "    return labels, score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _recompute_centers( X, labels, n_clusters):\n",
      "    \"\"\"\n",
      "    Computation of cluster centers / means.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    X: array-like, shape (n_samples, n_features)\n",
      "\n",
      "    labels: array of integers, shape (n_samples)\n",
      "        Current label assignment\n",
      "\n",
      "    n_clusters: int\n",
      "        Number of desired clusters\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    centers: array, shape (n_clusters, n_features)\n",
      "        The resulting centers\n",
      "    \"\"\"\n",
      "\n",
      "    n_samples = X.shape[0]\n",
      "    n_features = X.shape[1]\n",
      "   \n",
      "    # Initialize centers to all zero\n",
      "    centers = np.zeros((n_clusters, n_features))\n",
      "    n_samples_in_cluster = bincount(labels, minlength=n_clusters)\n",
      "\n",
      "\n",
      "    # Compute a center for each label\n",
      "    # For each label, average over samples and features\n",
      "    #TODO: IMPLEMENT\n",
      "    for i in range(n_samples):\n",
      "    for j in range(n_features):\n",
      "        centers[labels[i], j] += X[i, j]\n",
      "\n",
      "    # Normalize by the size of the cluster\n",
      "    centers /= n_samples_in_cluster[:, np.newaxis]\n",
      "\n",
      "    return centers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def k_means(X, n_clusters,\n",
      "            n_init=10, max_iter=10, verbose=False,\n",
      "            tol=1e-4, random_state=None):\n",
      "    \"\"\"K-means clustering algorithm.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "        The observations to cluster.\n",
      "\n",
      "    n_clusters : int\n",
      "        The number of clusters to form as well as the number of\n",
      "        centroids to generate.\n",
      "\n",
      "    max_iter : int, optional, default 300\n",
      "        Maximum number of iterations of the k-means algorithm to run.\n",
      "\n",
      "    n_init : int, optional, default: 10\n",
      "        Number of time the k-means algorithm will be run with different\n",
      "        centroid seeds. The final results will be the best output of\n",
      "        n_init consecutive runs in terms of score.\n",
      "\n",
      "    verbose : boolean, optional\n",
      "        Verbosity mode.\n",
      "\n",
      "    random_state : integer or numpy.RandomState, optional\n",
      "        The generator used to initialize the centers. If an integer is\n",
      "        given, it fixes the seed. Defaults to the global numpy random\n",
      "        number generator.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    centroid : float ndarray with shape (k, n_features)\n",
      "        Centroids found at the last iteration of k-means.\n",
      "\n",
      "    label : integer ndarray with shape (n_samples,)\n",
      "        label[i] is the code or index of the centroid the\n",
      "        i'th observation is closest to.\n",
      "\n",
      "    score : float\n",
      "        The final value of the score criterion (sum of squared distances to\n",
      "        the closest centroid for all observations in the training set).\n",
      "\n",
      "    \"\"\"\n",
      "    random_state = check_random_state(random_state)\n",
      "    best_labels, best_score, best_centers = None, np.infty, None\n",
      "\n",
      "    # We are going to `n_init` random starts and return the best one\n",
      "    for it in range(n_init):\n",
      "        # run a k-means once\n",
      "        labels, score, centers = _kmeans_single(X, n_clusters, max_iter=max_iter, \n",
      "          verbose=verbose, random_state=random_state)\n",
      "        # determine if these results are the best so far\n",
      "        #TODO: IMPLEMENT\n",
      "        if best_score is None or score < best_score:\n",
      "            #set the best values\n",
      "            best_labels = labels.copy()\n",
      "            best_centers = centers.copy()\n",
      "            best_score = score\n",
      "    return best_centers, best_labels, best_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _kmeans_single(X, n_clusters, max_iter=10, verbose=False, random_state=None):\n",
      "    \"\"\"A single run of k-means, assumes preparation completed prior.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    X: array-like of floats, shape (n_samples, n_features)\n",
      "        The observations to cluster.\n",
      "\n",
      "    n_clusters: int\n",
      "        The number of clusters to form as well as the number of\n",
      "        centroids to generate.\n",
      "\n",
      "    max_iter: int, optional, default 10\n",
      "        Maximum number of iterations of the k-means algorithm to run.\n",
      "\n",
      "    verbose: boolean, optional\n",
      "        Verbosity mode\n",
      "\n",
      "    random_state: integer or numpy.RandomState, optional\n",
      "        The generator used to initialize the centers. If an integer is\n",
      "        given, it fixes the seed. Defaults to the global numpy random\n",
      "        number generator.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    centroid: float ndarray with shape (k, n_features)\n",
      "        Centroids found at the last iteration of k-means.\n",
      "\n",
      "    label: integer ndarray with shape (n_samples,)\n",
      "        label[i] is the code or index of the centroid the\n",
      "        i'th observation is closest to.\n",
      "\n",
      "    score: float\n",
      "        The final value of the score criterion (sum of squared distances to\n",
      "        the closest centroid for all observations in the training set).\n",
      "    \"\"\"\n",
      "    random_state = check_random_state(random_state)\n",
      "\n",
      "    best_labels, best_score, best_centers = None, np.infty, None\n",
      "    # init\n",
      "    centers = _init_random_centroids(X, n_clusters, random_state=random_state)\n",
      "    if verbose:\n",
      "        print('Initialization complete')\n",
      "\n",
      "    for i in range(max_iter):\n",
      "        # Figure out the labels, given the centers\n",
      "        labels, score = _compute_labels_and_score(X, centers)\n",
      "\n",
      "        # Recompute the centers given the labels and data\n",
      "        centers = _recompute_centers(X, labels, n_clusters)\n",
      "\n",
      "        # Save the best run\n",
      "        #TODO: IMPLEMENT\n",
      "        if best_score is None or score < best_score:\n",
      "            best_labels = labels.copy()\n",
      "            best_centers = centers.copy()\n",
      "            best_score = score\n",
      "        # Is this run better than the last run?\n",
      "            # If so, update best_centers, best_labels, best_score\n",
      "\n",
      "    return best_labels, best_score, best_centers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _init_random_centroids(X, k, random_state=None):\n",
      "    \"\"\"Compute the initial centroids\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "\n",
      "    X: array, shape (n_samples, n_features)\n",
      "\n",
      "    k: int\n",
      "        number of centroids\n",
      "\n",
      "    random_state: integer or numpy.RandomState, optional\n",
      "        The generator used to initialize the centers. If an integer is\n",
      "        given, it fixes the seed. Defaults to the global numpy random\n",
      "        number generator.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    centers: array, shape(k, n_features)\n",
      "    \"\"\"\n",
      "    random_state = check_random_state(random_state)\n",
      "    n_samples = X.shape[0]\n",
      "\n",
      "    seeds = random_state.permutation(n_samples)[:k]\n",
      "    centers = X[seeds]\n",
      "\n",
      "    return centers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class KMeans():\n",
      "    \"\"\"K-Means clustering\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "\n",
      "    n_clusters : int, optional, default: 8\n",
      "        The number of clusters to form as well as the number of\n",
      "        centroids to generate.\n",
      "\n",
      "    max_iter : int\n",
      "        Maximum number of iterations of the k-means algorithm for a\n",
      "        single run.\n",
      "\n",
      "    n_init : int, optional, default: 10\n",
      "        Number of time the k-means algorithm will be run with different\n",
      "        centroid seeds. The final results will be the best output of\n",
      "        n_init consecutive runs in terms of score.\n",
      "\n",
      "    random_state : integer or numpy.RandomState, optional\n",
      "        The generator used to initialize the centers. If an integer is\n",
      "        given, it fixes the seed. Defaults to the global numpy random\n",
      "        number generator.\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    `cluster_centers_` : array, [n_clusters, n_features]\n",
      "        Coordinates of cluster centers\n",
      "\n",
      "    `labels_` :\n",
      "        Labels of each point\n",
      "\n",
      "    `score_` : float\n",
      "        The value of the score criterion associated with the chosen\n",
      "        partition.\n",
      "\n",
      "   \"\"\"\n",
      "\n",
      "    def __init__(self, n_clusters=8, n_init=10, max_iter=10, verbose=0, random_state=None):\n",
      "\n",
      "        self.n_clusters = n_clusters\n",
      "        self.max_iter = max_iter\n",
      "        self.n_init = n_init\n",
      "        self.verbose = verbose\n",
      "        self.random_state = random_state\n",
      "\n",
      "    def _check_fit_data(self, X):\n",
      "        \"\"\"Verify that the number of samples given is larger than k\"\"\"\n",
      "        if X.shape[0] < self.n_clusters:\n",
      "            raise ValueError(\"n_samples=%d should be >= n_clusters=%d\" % (\n",
      "                X.shape[0], self.n_clusters))\n",
      "        return X\n",
      "\n",
      "    def _check_test_data(self, X):\n",
      "        n_samples, n_features = X.shape\n",
      "        expected_n_features = self.cluster_centers_.shape[1]\n",
      "        if not n_features == expected_n_features:\n",
      "            raise ValueError(\"Incorrect number of features. \"\n",
      "                             \"Got %d features, expected %d\" % (\n",
      "                                 n_features, expected_n_features))\n",
      "\n",
      "        return X\n",
      "\n",
      "    def _check_fitted(self):\n",
      "        if not hasattr(self, \"cluster_centers_\"):\n",
      "            raise AttributeError(\"Model has not been trained yet.\")\n",
      "\n",
      "    def fit(self, X, y=None):\n",
      "        \"\"\"Compute k-means clustering.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like or sparse matrix, shape=(n_samples, n_features)\n",
      "        \"\"\"\n",
      "        random_state = check_random_state(self.random_state)\n",
      "        X = self._check_fit_data(X)\n",
      "\n",
      "        self.cluster_centers_, self.labels_, self.score_ = k_means(\n",
      "            X, n_clusters=self.n_clusters, n_init=self.n_init,\n",
      "            max_iter=self.max_iter, verbose=self.verbose, random_state=random_state)\n",
      "        return self\n",
      "\n",
      "    def fit_predict(self, X):\n",
      "        \"\"\"Compute cluster centers and predict cluster index for each sample.\n",
      "\n",
      "        Convenience method; equivalent to calling fit(X) followed by\n",
      "        predict(X).\n",
      "        \"\"\"\n",
      "        return self.fit(X).labels_\n",
      "\n",
      "    def transform(self, X, y=None):\n",
      "        \"\"\"Transform X to a cluster-distance space\n",
      "\n",
      "        In the new space, each dimension is the distance to the cluster\n",
      "        centers.  Note that even if X is sparse, the array returned by\n",
      "        `transform` will typically be dense.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      "            New data to transform.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        X_new : array, shape [n_samples, k]\n",
      "            X transformed in the new space.\n",
      "        \"\"\"\n",
      "        self._check_fitted()\n",
      "        X = self._check_test_data(X)\n",
      "        return euclidean_distances(X, self.cluster_centers_)\n",
      "\n",
      "    def predict(self, X):\n",
      "        \"\"\"Predict the closest cluster each sample in X belongs to.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      "            New data to predict.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        labels : array, shape [n_samples,]\n",
      "            Index of the cluster each sample belongs to.\n",
      "        \"\"\"\n",
      "        self._check_fitted()\n",
      "        X = self._check_test_data(X)\n",
      "        return _compute_labels_and_score(X, self.cluster_centers_)[0]\n",
      "\n",
      "    def score(self, X):\n",
      "        \"\"\"Opposite of the value of X on the K-means objective.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      "            New data.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        score : float\n",
      "            Opposite of the value of X on the K-means objective.\n",
      "        \"\"\"\n",
      "        self._check_fitted()\n",
      "        X = self._check_test_data(X)\n",
      "        return -_compute_labels_and_score(X, self.cluster_centers_)[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_digits\n",
      "digits = load_digits()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import scale\n",
      "data = scale(digits.data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.DataFrame(data)\n",
      "plt.scatter(data[:, 0], data[:, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "<matplotlib.collections.PathCollection at 0x10c3eca50>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD9CAYAAACx+XApAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFlpJREFUeJzt3Xt0VOW9xvFnk4RbIyBYJyYTDSQkhAAh4ZKK7WIUgmhN\n5AicAl5SKG1XvRWXWtHaY+wSDLUuDmqVc7DSgBboQQ4XBSxYhlUvkHI9lGvQZJkLiQoCBoITkn3+\nCGCMXNO9ZzK8389as1Zm3PO+v58b8vDu2bO3Zdu2AADmahPqAgAAoUUQAIDhCAIAMBxBAACGIwgA\nwHAEAQAYrkVBMGnSpNc8Hk913759d5x+7dChQ12zs7PXJCcn7xsxYsRfDx8+3MW5MgEAbmlREEyc\nOHHu6tWrRzZ9raCgYGp2dvaaffv2JQ8bNuzdgoKCqc6UCABwk9XSL5SVlpYm5OTkrNixY0dfSerV\nq9ee9evXD/V4PNVVVVUxPp/Pv2fPnl6OVgsAcFykUwNVV1d7PB5PtSR5PJ7q6upqT/NtLMvia8wA\n0AK2bVtuje3Kh8WWZdnn+qVv2/Zl+3jqqadCXgP90Rv9XX4PtzkWBKcPCUnSgQMHrrn66qs/dWps\nAIB7HAuC3Nzc5YWFhXmSVFhYmDdq1KilTo0NAHBPi4Jg/PjxC4YMGfLB3r17U+Lj48vmzp07cerU\nqQVr1qzJTk5O3ve3v/3tpqlTpxY4XWxr5/P5Ql2Cqy7n/i7n3iT6w/m1+KyhFk1mWXYw5wOAy4Fl\nWbLD7cNiAED4IAgAwHAEAQAYjiAAAMMRBABgOIIAAAxHEACA4QgCADAcQQAAhiMIAMBwBAEAGI4g\nAADDEQQAYDiCAAAMRxAAgOEIAgAwHEEAAIYjCADAcAQBABiOIAAAwxEEMN6LL76oyMgrZVnt1KlT\nvLZt2xbqkoCgsmzbDt5klmUHcz7gQj788EMNGTJc0iJJN0gqULt2c3XixKchrgz4mmVZsm3bcmt8\nVgQw2oIFCyT5JN0m6UpJBfrqqyP65JNPQloXEEwEAYzm8XgkFUs6eeqVTyQ16KqrrgpdUUCQcWgI\nRgsEAvJ4knT4sEfSDyS9odzcH2jZssWhLg04w+1DQwQBjHfixAk99NBDKikp0ciRIzVlypRQlwR8\nA0EAAIbjw2IAgKscDYJnn3328bS0tJ19+/bdMWHChD9/9dVX7ZwcHwDgPMeCoLS0NGHOnDk/3bJl\nS+aOHTv61tfXRyxcuHCcU+MDANwR6dRAnTp1OhoVFVV3/PjxjhEREfXHjx/vGBcXV+HU+AAAdzgW\nBF27dj308MMPP3/ttdd+0qFDh9qbb775neHDh69tvl1+fv6Zn30+n3w+n1MlAMBlwe/3y+/3B20+\nx84a+uijjxJzcnJW/P3vf/9B586dj4wdO/Z/xowZs/jOO+9848xknDUEAJcsbM4a2rRp08AhQ4Z8\n0K1bt4ORkZEn77jjjiUffPDBEKfGBwC4w7Eg6NWr154NGzZ8r7a2toNt29batWuH9+7de5dT4wMA\n3OFYEKSnp2+/55575g0cOHBTv379/k+Sfvazn/23U+MDANzBN4sBoJULm88IAADhiSAAAMMRBABg\nOIIAxqutrVVOTo769eunJ554ItTlAEHHh8UwWiAQUHR0rOrqYtR4z+LFyszsqc2bN4S6NOAMtz8s\nduwSE0A4uu+++1RX11nSVklRkn6lLVt6qaamRtHR0SGuDggODg3BaI03qU9VYwhIUg9JbVRaWhqy\nmoBgIwhgtMmTJ0taJ2mtpFpJT0tqrz59+oS0LiCYCAIYbezYsZo0aZykUZKiZVmztGzZ/FCXBQQV\nHxYDp9TX1ysiIiLUZQDfwjeLgSAhBGAqggAADEcQAIDhCAIAMBxBAACGIwgAwHAEAQAYjiAAAMMR\nBABgOIIAAAxHEACA4QgCADAcQQAAhiMIAMBwBAGM98gjj8iyOsuyOigy8iqtX78+1CUBQcX9CGC0\n5cuX6/bbx0t6XY03r58hy/qjGhoOh7gy4Gtu34+AIIDRRo4cqXfesSStOvVKg6QO2rVrm1JTU0NY\nGfA1bkwDuCgmJkZSiaT6U69USGpQbGxs6IoCgszRIDh8+HCXMWPGLE5NTd3du3fvXRs2bPiek+MD\nTnvllVcUEfGppO9LekzSIKWk9Fbnzp1DXBkQPI4eGsrLyyscOnTo+kmTJr128uTJyGPHjn2nc+fO\nR85MxqEhtEJHjhzRbbfdpsrKSt10002aM2dOqEsCviFsPiM4cuRI54yMjK0ff/xxj3NORhAAwCVz\nOwginRqopKSk+3e/+93PJk6cOHf79u3pAwYM2Dxr1qxfduzY8XjT7fLz88/87PP55PP5nCoBAC4L\nfr9ffr8/aPM5tiLYtGnTwOuvv/7DDz74YMigQYP+MWXKlP/s1KnT0d/+9rf/cWYyVgQAcMnC5qwh\nr9db7vV6ywcNGvQPSRozZsziLVu2ZDo1PgDAHY4FQUxMTFV8fHzZvn37kiVp7dq1w9PS0nY6NT4A\nwB2OnjW0ffv29MmTJ78aCATaJiYmfjR37tyJnDUEAP+asDlr6KImIwgA4JKFzWcEAIDwRBAAgOEI\nAgAwHEEAAIYjCADAcAQBABiOIAAAwxEEMN6hQ4fUvn17tWnTRtddd12oywGCji+UwWi1tbXq2DFG\nUqyk6yX9ryyrVg0NJ0JcGfA1vlAGuKjxVpXdJG2X9JqkItl2g/bv3x/awoAgIghgtOPHj0vqLant\nqVeSJLXRsmXLQlcUEGQEAYw2bNgwSeskrZcUkDRdUlvde++9Ia0LCCY+I4DxrrjiCtXUNEiqlXSF\ncnKGavny5aEuCziDq48CQXLo0CF17do11GUA30IQAIDhOGsIAOAqggAADEcQAIDhCAIAMBxBAACG\nIwgAwHAEAQAYjiAAAMMRBABgOIIAAAxHEACA4QgCADAcQQAAhnM8COrr6yMyMjK25uTkrHB6bMAN\nlmXJsjrLsjrKsrqoR48eoS4JCCrHg2DWrFm/7N279y7LsrjeNFq9xvsPdJD0qqT9kvJUUnIwtEUB\nQeZoEJSXl3tXrlx56+TJk19189rZgFO++OILSUMljZUUK2mmpBMaPnx4SOsCginSycEeeuihmc89\n99yjR48e7XSubfLz88/87PP55PP5nCwBaIFSSfWSIiQdkNSg8ePHh7QimM3v98vv9wdtPsfuUPbW\nW2/dtmrVqlv+8Ic/3Of3+33PP//8wytWrMj5xmTcoQytzJIlSzR69I8lpatxZfCapC9k27UhrQto\nKmxuVfnEE09Mnz9//t2RkZEnT5w40f7o0aOdRo8e/ea8efPuOTMZQYBWaNasWZoyZYokS5It/oyi\ntQmbIGhq/fr1Q3//+98/wooAAP51YXvPYs4aAoDw4MqK4JyTsSIAgEsWtisCAEB4IAgAwHAEAQAY\njiAAAMMRBABgOIIAAAxHEACA4QgCADAcQQAAhiMIAMBwBAEAGI4ggPH8fv+p+xY3PgDTcNE5GK20\ntFTdu6dL8kjKkrRCUo1s+2RoCwOa4KJzgIu6d+8u6UpJOyTNl7RRUhvNnz8/pHUBwcSKAEZrPBT0\nQ0lvnXrFltRBsbHdVFFREbrCgCZYEQCuWyfpfTXewP53kqL0/vvvh7YkIIhYEcB4jauCDpK+kvQd\nSV9y32K0KqwIAJfZti3bPq7f/ObXsu2jhACMw4oAAFo5VgQAAFcRBABgOIIAAAxHEACA4QgCADAc\nQQAAhiMIAMBwBAEAGI4gAADDORoEZWVl8TfeeOO6tLS0nX369PnnCy+88KCT4wMAnOfoJSaqqqpi\nqqqqYvr377+tpqYmesCAAZuXLl06KjU1dbfEJSYAoCXC6hITMTExVf37998mSdHR0TWpqam7Kysr\nY52cAwDgrEi3Bi4tLU3YunVrRlZW1samr+fn55/52efzyefzuVUCAIQlv98vv98ftPlcufpoTU1N\ntM/n8z/55JPPjBo1aumZyTg0hFao8X4EnSWdVOO/jY5wKWq0KmF1aEiS6urqokaPHv3mXXfd9XrT\nEABao69vSvOypJ2SJkjqFNKagGBzdEVg27aVl5dX2K1bt4MzZ8586FuTsSJAK9MYBDdLWn3qlQY1\nBkOAVQFajbBaEbz//vs3vP7663etW7fuxoyMjK0ZGRlbV69ePdLJOQDnlakxACSpSlKDMjIyQlgP\nEFzcoQxGy8zM1Nat+yUNlDRU0quSPpdt14a2MKAJt1cEBAGMFxcXp8rKSjUukBs4JIRWhyAAAMOF\n1WcEAIDwQxAAgOEIAgAwHEEAAIYjCADAcAQBABiOIAAAwxEEAGA4ggAADEcQAIDhCAIAMBxBAACG\nIwgAwHAEAYyXn58vy7LOPADTEAQwWn5+vp5+eqak7pL+XVInWRZ/LWAW7kcAozWuAK6VtFdSe0m7\nJPVXXNzVKi8vD2ltwGncjwBwXV81hoAk9ZbURhUVFSGsBwguggCQX1KRJFvSTElReuqpp0JaERBM\nHBqC8RoPD7WTdFJSR0lfct9itCocGgJcZtu2nnpqqqR62fZRQgDGYUUAAK0cKwIAgKsIAgAwHEEA\nAIYjCADAcAQBABiOIAAAwzkaBKtXrx7Zq1evPT179iyeMWPGY06ODQBwh2PfI6ivr49ISUnZu3bt\n2uFxcXEVgwYN+seCBQvGp6am7j4zGd8jAIBLFjbfIygqKhqclJS0PyEhoTQqKqpu3LhxC5ctW3a7\nU+MDANwR6dRAFRUVcfHx8WWnn3u93vKNGzdmNd8uPz//zM8+n08+n8+pEgDgsuD3++X3+4M2n2NB\nYFnWRR3zaRoEAIBva/6P5KefftrV+Rw7NBQXF1dRVlYWf/p5WVlZvNfr5c4eANDKORYEAwcO3FRc\nXNyztLQ0IRAItF20aNGPcnNzlzs1PgDAHY4dGoqMjDz50ksv3X/zzTe/U19fH/GTn/zkj03PGAJa\nq8b7EXSWVC8pQtIRLkUNo3AZahitMQQ6SHpF0vclzZC0SLZ9JKR1AU25ffooQQCjNQbBCEnvnHql\nXo13KQuwKkCrETbfIwDCV4WkhlM/f9bkZ8AMjn1GAISvTySNlOST9F+SomTbdSGtCAgmDg3BeI2H\nhyQpSlIdh4TQ6rh9aIgVAYzHL36Yjs8IAMBwBAEAGI4gAADDEQQAYDiCAAAMRxAAgOEIAgAwHEEA\nAIYjCADAcAQBABiOIAAAwxEEAGA4ggAADEcQAIDhCAIAMBxBAACGIwgAwHAEAQAYjiAAAMMRBABg\nOIIAAAxHEACA4QgCB/n9/lCX4KrLub/LuTeJ/nB+jgXBo48++lxqauru9PT07XfccceSI0eOdHZq\n7HBxuf9hvJz7u5x7k+gP5+dYEIwYMeKvO3fuTNu+fXt6cnLyvmefffZxp8YGALjHsSDIzs5e06ZN\nmwZJysrK2lheXu51amwAgHss27YdHzQnJ2fF+PHjF0yYMOHP35jMspyfDAAMYNu25dbYkZeycXZ2\n9pqqqqqY5q9Pnz79iZycnBWSNG3atF+3bds20DwEJHcbAQC0jKMrgj/96U8/njNnzk/ffffdYe3b\ntz/h2MAAANdc0orgfFavXj3yueeee3T9+vVDCQEACB+OrQh69uxZHAgE2nbt2vWQJF1//fUfvvzy\ny/c6MjgAwD22bbfocfDgwa7Dhw9f07Nnz33Z2dl//eKLL7qcbbtVq1aNTElJ2ZOUlFRcUFDw2IXe\nf/Dgwa4+n29ddHT0l/fff/+LTccaOnSoPyUlZU///v239u/ff+tnn312VUvrb229bdq0aUCfPn12\nJCUlFT/44IOz3OjL7f5s29b06dMfT0pKKk5JSdnzzjvvjAjmvjtXvU0fDzzwwAtJSUnF/fr1275l\ny5YMN3p16xHM/kpKShLat29fe3p//eIXv3g5HPv7y1/+MrZ3794727RpU7958+bMpmMFc/8Fs7eW\n7LsWN/boo4/+bsaMGb+ybVsFBQWPPfbYYwXNtzl58mREYmLi/pKSkoRAIBCVnp6+bdeuXanne/+x\nY8c6vvfeezfMnj37581/Wfp8vnXNd6Ybj1D0NmjQoKKNGzcOtm1bt9xyy8pVq1aNDLf+du7c2Ts9\nPX1bIBCIKikpSUhMTNzf0NBgBWPfna/e04+333771ltuuWWlbdvasGFDVlZW1gYne62vr29zufRX\nUlKS0KdPnx1u/11zu7/du3f32rt3b3LzP3/B3H/B7q0l+67F3yNYvnx5bl5eXqEk5eXlFS5dunRU\n822KiooGJyUl7U9ISCiNioqqGzdu3MJly5bdfr73d+zY8fgNN9zwfrt27b46xwrG9TOPgt3bgQMH\nrvnyyy+vGDx4cJEk3XPPPfPONmdr72/ZsmW3jx8/fkFUVFRdQkJCaVJS0v6NGzdmnR7TzX13vnrP\n1ndWVtbGw4cPd6mqqopxqteioqLBl0t/weZWf7169dqTnJy8r/l8wdx/we6tJVocBNXV1R6Px1Mt\nSR6Pp7q6utrTfJuKioq4+Pj4stPPvV5veUVFRdzFvP9c3znIy8srzMjI2PrMM8882dLaLyTYvVVU\nVMR5vd7y08/j4uIqTo/lBrf6q6ysjG3ah9frLa+srIw9/dzNfXe+ei+0TWVlZawTvbq5z4LdnySV\nlJR0z8jI2Orz+fzvvffe993qzc3+ziWY+y/YvUmXvu/Oe9bQub43MG3atF83fW5Zln22X9zNX7Nt\n2zrXdhfzZbM33njjztjY2Mqampro0aNHvzl//vy777777vkXet/ZtLbenNba+nNy353Nxf4/vphV\nSUt7dXM/B7u/2NjYyrKysvgrr7zyiy1btmSOGjVq6c6dO9OuuOKKLy+9+gtzsj+3a3BrXKd6a8m+\nO28QrFmzJvtc/83j8VRXVVXFxMTEVB04cOCaq6+++tPm28TFxVWUlZXFn35eXl7ujYuLq7jY95+t\nQUmKjo6umTBhwp+LiooGt/SXSWvqLS4urqLpJTmajtVSoejvfO9xct+dTfO5y8rK4pv+i+9c9Xm9\n3vK6urooJ3t1Q7D7a9u2baBt27YBScrMzNySmJj4UXFxcc/MzMwtrb2/s733QvO5uf+C3VtL9l2L\nDw3l5uYuLywszJOkwsLCvFGjRi1tvs3AgQM3FRcX9ywtLU0IBAJtFy1a9KPc3NzlF/P+5ulYX18f\n8fnnn18lSXV1dVErVqzI6du3746W1t+aervmmmsOdOrU6ejGjRuzbNu25s+ff/fZ5mzt/eXm5i5f\nuHDhuEAg0LakpKR7cXFxz8GDBxcFY9+dr96mfc+bN+8eSdqwYcP3unTpctjj8VQ72auTPYWyv88/\n//yq+vr6CEn6+OOPexQXF/fs0aPHx+HWX1NN/94Fc/8Fu7cW7buWfhJ+8ODBrsOGDVvb/LSzioqK\n2FtvvfXt09utXLnyluTk5L2JiYn7p0+f/viF3m/btq677rrSrl27HoyOjv7S6/WW7d69u9exY8c6\nDhgwYFO/fv22p6Wl/XPKlCkzT5+R4vQj2L3Z9tenjyYmJu5/4IEHXnCjr2D0N23atCcSExP3p6Sk\n7Fm9evXNtm2rpqbmO8HYd2erd/bs2T+fPXv2z09vc999972UmJi4v1+/ftubnmnhVK9uPoLZ35tv\nvnlHWlraP/v37781MzNz81tvvfXDcOxvyZIl/+b1esvat29f6/F4qkaOHLkqFPsvmL0tXrx49KXu\nO1cuOgcACB/coQwADEcQAIDhCAIAMBxBAACGIwgAwHAEAQAY7v8Ba/joJ3gqTzMAAAAASUVORK5C\nYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10c3c66d0>"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "array([[ 0.        , -0.33501649, -0.04308102, ..., -1.14664746,\n",
        "        -0.5056698 , -0.19600752],\n",
        "       [ 0.        , -0.33501649, -1.09493684, ...,  0.54856067,\n",
        "        -0.5056698 , -0.19600752],\n",
        "       [ 0.        , -0.33501649, -1.09493684, ...,  1.56568555,\n",
        "         1.6951369 , -0.19600752],\n",
        "       ..., \n",
        "       [ 0.        , -0.33501649, -0.88456568, ..., -0.12952258,\n",
        "        -0.5056698 , -0.19600752],\n",
        "       [ 0.        , -0.33501649, -0.67419451, ...,  0.8876023 ,\n",
        "        -0.5056698 , -0.19600752],\n",
        "       [ 0.        , -0.33501649,  1.00877481, ...,  0.8876023 ,\n",
        "        -0.26113572, -0.19600752]])"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}